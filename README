################################################################
# drrec
################################################################
ssh xiaojie@10.100.229.246 # cpu xw # song
ssh xiaojie@10.100.228.181 # gpu xw # coat, risk
ssh xiaojie@10.100.228.158 # gpu cz # coat, risk


conda create -n drrec python=3.6
pip install --ignore-installed -r requirements.txt
pip install -e .

################################################################
# learning theory
################################################################
http://www.shivani-agarwal.net/Teaching/E0370/Aug-2011/Lectures/3.pdf

################################################################
# latex
################################################################
http://www.danielherber.com/latex.php?option=post_5
https://tex.stackexchange.com/questions/401490/how-to-reduce-the-space-around-a-table-spanning-two-columns

\begin{figure*}[!t]
\begin{minipage}[t]{0.5\linewidth}
\centering
\begin{figure}[H] %% the package "float" and [H] is necessary for this
\centering
\begin{subfigure}{0.476\textwidth}
  \centering
  \includegraphics[width=1.00\linewidth]{fig/mae_error.eps}
  \caption{Inaccurate error imputation.}
  \label{fig:mae error}
\end{subfigure}
\hspace*{-0.75em} % \hfill
\begin{subfigure}{0.476\textwidth}
  \centering
  \includegraphics[width=1.00\linewidth]{fig/mae_beta.eps}
  \caption{Inaccurate propensities.}
  \label{fig:mae beta}
\end{subfigure}
\caption{Robustness of the DR, EIB, IPS, and SNIPS estimators.}
\end{figure}
\end{minipage}
% \hspace{-1.0em}
\begin{minipage}[t]{0.5\linewidth}
\centering
\begin{figure}[H] %% the package "float" and [H] is necessary for this
\centering
\begin{subfigure}{0.476\textwidth}
  \centering
  \includegraphics[width=1.00\linewidth]{fig/mae_omega.eps}
  \caption{Varying the weight $\imputationQuality$.}
  \label{fig:mae omega}
\end{subfigure}
\hspace*{-0.75em} % \hfill
\begin{subfigure}{0.476\textwidth}
  \centering
  \includegraphics[width=1.00\linewidth]{fig/mae_gamma.eps}
  \caption{Varying the imputed value $\anImputedRating$.}
  \label{fig:mae gamma}
\end{subfigure}
\caption{Effects of parameters on the accuracy of the DR estimator.}
\end{figure}
\end{minipage}
\end{figure*}


  Our DR estimator, $e_{\rm{DR}}=\hat{e}+o(e-\hat{e})/\hat{p}$, of the true error ($e=|\hat{r}-r|$) has a smaller bias (\mytextbf{0.1}) than the EIB ($e_{\rm{EIB}}=\hat{e}+oe-o\hat{e}$) and IPS ($e_{\rm{IPS}}=oe/\hat{p}$) estimators. The imputed error $\hat{e}=|\hat{r}-4.5|$.

################################################################
# backup
################################################################
https://tex.stackexchange.com/questions/429393/draw-sine-waves
https://tex.stackexchange.com/questions/101576/how-to-draw-horizontalrow-legend-without-the-surronding-rectangle

\newcommand{\toySColumnR}{0.000\linewidth}
\newcommand{\toySColumnRhat}{0.210\linewidth}
\newcommand{\toySColumnO}{0.405\linewidth}
\newcommand{\toySColumnE}{0.595\linewidth}
\newcommand{\toySColumnP}{0.795\linewidth}
\newcommand{\toySTextY}{0.64}
\newcommand{\toyLColumnW}{0.32\linewidth}
\newcommand{\toyLMatrixY}{0.72}
\newcommand{\toyEIBTextY}{0.08} % toyLMatrixY - toySTextY
\newcommand{\toyEIBMissTY}{1.36} % 2 * toyLMatrixY - toyEIBTextY
\newcommand{\toyEIBMissSTopY}{1.60} % toyEIBMissTY + 0.24
\newcommand{\toyEIBMissSBtmY}{-1.56} % toyIPSBtmY
\newcommand{\toyIPSTextY}{-1.28} % -toyLMatrixY - toySTextY
\newcommand{\toyLSquareLX}{1.62}
\newcommand{\toyLSquareIX}{-0.60}
\newcommand{\toyLSquareMX}{0.58} % -toyLSquareIX - 0.04
\newcommand{\toyLSquareRX}{1.54}
\newcommand{\toyLSquareLTX}{1.48}
\newcommand{\toyLSquareRTX}{0.92}
\newcommand{\toyLSquareEIBY}{1.20}
\newcommand{\toyLSquareIPSY}{0.80} % 2 - toyLSquareEIBY
\newcommand{\toyEIBTopY}{1.16}
\newcommand{\toyEIBBtmY}{-0.20}
\newcommand{\toyIPSTopY}{-0.28} % toyEIBTopY - 2 * toyLMatrixY
\newcommand{\toyIPSBtmY}{-1.56} % toyIPSTopY + toyEIBBtmY - toyEIBTopY
\newcommand{\toyDRTopY}{1.16} % toyEIBTopY + 0.00
\newcommand{\toyDRBtmY}{-1.56} % toyIPSBtmY - 0.00
\newcommand{\toyArrowCenterBX}{0.66}
\newcommand{\toyArrowCenterEX}{0.34}
\newcommand{\toyArrowLeftBX}{1.52}
\newcommand{\toyArrowLeftEX}{1.36} % toyArrowCenterEX + 1
\tikzstyle{toySExampleS} = [
  every left delimiter/.style={xshift=0.05cm},
  every right delimiter/.style={xshift=-0.05cm},
]
\tikzstyle{toyLExampleS} = [
  every left delimiter/.style={xshift=0.05cm},
  every right delimiter/.style={xshift=-0.05cm},
]
\tikzstyle{toySMatrixS} = [
  column sep=-0.65ex, inner sep=0.0pt, matrix of math nodes, 
  nodes={ % draw, very thin,
    minimum width=1.35em, minimum height=1.20em, 
    inner sep=0.0pt, outer sep=0.0pt,},
  left delimiter={[}, right delimiter={]},
]
\tikzstyle{toyLMatrixS} = [
  column sep=-0.20ex, inner sep=0.0pt, matrix of math nodes, 
  nodes={ % draw, very thin,
    minimum width=1.80em, minimum height=1.20em, 
    inner sep=0.0pt, outer sep=0.0pt,},
  left delimiter={[}, right delimiter={]},
]

\matrix (R) [toySMatrixS] at (\toySColumnR,0) {
  1 & 1 & 5 \\
  1 & 1 & 5 \\
};
\matrix (R_hat) [toySMatrixS] at (\toySColumnRhat,0) {
  3 & 3 & 4 \\
  3 & 3 & 4 \\
};
\matrix (O) [toySMatrixS] at (\toySColumnO,0) {
  1 & 0 & 0 \\
  0 & 0 & 1 \\
};
\matrix (E) [toySMatrixS] at (\toySColumnE,0) {
  2 & 2 & 1 \\
  2 & 2 & 1 \\
};
\matrix (P) [toyLMatrixS] at (\toySColumnP,0) {
  \nicefrac{1}{4} & \nicefrac{1}{4} & \nicefrac{1}{2} \\
  \nicefrac{1}{4} & \nicefrac{1}{4} & \nicefrac{1}{2} \\
%   \frac{1}{4} & \frac{1}{4} & \frac{1}{2} \\
%   \frac{1}{4} & \frac{1}{4} & \frac{1}{2} \\
};

\node at (\toySColumnO, \toySTextY) {
  $^{*}$Row and column denote user and item (matrix indices omitted).
};
\node at (\toySColumnR, -\toySTextY) {True rating $r$.};
\node at (\toySColumnRhat, -\toySTextY) {Prediction $\hat{r}$.};
\node at (\toySColumnO, -\toySTextY) {Indicator $o$.};
\node at (\toySColumnE, -\toySTextY) {True error $e$.};
\node at (\toySColumnP, -\toySTextY) {Propensity $p$.};

\matrix (EIB) [toyLMatrixS] at (-1*\toyLColumnW,\toyLMatrixY) {
  2 & 1.5 & 0.5 \\
  1.5 & 1.5 & 1 \\
};
\matrix (IPS) [toyLMatrixS] at (-1*\toyLColumnW,-\toyLMatrixY) {
  6.7 & 0 & 0 \\
  0 & 0 & 2.5 \\
};
\matrix (E_hat) [toyLMatrixS] at (0*\toyLColumnW,\toyLMatrixY) {
  1.5 & 1.5 & 0.5 \\
  1.5 & 1.5 & 0.5 \\
};
\matrix (P_hat) [toyLMatrixS] at (0*\toyLColumnW,-\toyLMatrixY) {
  0.3 & 0.3 & 0.4 \\
  0.3 & 0.3 & 0.4 \\
};
\matrix (DR) [toyLMatrixS] at (1*\toyLColumnW,0) {
  3.2 & 1.5 & 0.5 \\
  1.5 & 1.5 & 1.7 \\
};
% \node [rectangle] at (1*\toyLColumnW,1.28*\toyLMatrixY) {\normalsize Our DR method.};


\draw [<-,solid,thick] (-\toyArrowCenterBX*\toyLColumnW,\toyLMatrixY)--(-\toyArrowCenterEX*\toyLColumnW,\toyLMatrixY);
\draw [<-,solid,thick] (-\toyArrowCenterBX*\toyLColumnW,-\toyLMatrixY)--(-\toyArrowCenterEX*\toyLColumnW,-\toyLMatrixY);
\draw [<-,solid,thick] (\toyArrowCenterBX*\toyLColumnW,0.04)--(\toyArrowCenterEX*\toyLColumnW,\toyLMatrixY);
\draw [<-,solid,thick] (\toyArrowCenterBX*\toyLColumnW,-0.04)--(\toyArrowCenterEX*\toyLColumnW,-\toyLMatrixY);

\draw [solid,black!16!red,thin] (-\toyLSquareLX*\toyLColumnW,\toyEIBTopY)--(\toyLSquareIX*\toyLColumnW,\toyEIBTopY)--(\toyLSquareIX*\toyLColumnW,\toyEIBBtmY)--(-\toyLSquareLX*\toyLColumnW,\toyEIBBtmY)--cycle;
\draw [solid,black!16!green,thin] (-\toyLSquareLX*\toyLColumnW,\toyIPSTopY)--(\toyLSquareIX*\toyLColumnW,\toyIPSTopY)--(\toyLSquareIX*\toyLColumnW,\toyIPSBtmY)--(-\toyLSquareLX*\toyLColumnW,\toyIPSBtmY)--cycle;
\draw [solid,black!16!blue,thin] (-\toyLSquareIX*\toyLColumnW,\toyDRTopY)--(\toyLSquareRX*\toyLColumnW,\toyDRTopY)--(\toyLSquareRX*\toyLColumnW,\toyDRBtmY)--(-\toyLSquareIX*\toyLColumnW,\toyDRBtmY)--cycle;
\draw [dashed,black!16!magenta,thin] (-\toyLSquareMX*\toyLColumnW,\toyEIBMissSTopY)--(\toyLSquareMX*\toyLColumnW,\toyEIBMissSTopY)--(\toyLSquareMX*\toyLColumnW,\toyEIBMissSBtmY)--(-\toyLSquareMX*\toyLColumnW,\toyEIBMissSBtmY)--cycle;


\node at (-1.10*\toyLColumnW,\toyEIBTextY) {$\big|{\textstyle\sum}e_{\rm{EIB}}-{\textstyle\sum}e\big|=\mytextbf{2}$};
\node at (-1.10*\toyLColumnW,\toyIPSTextY) {$\big|{\textstyle\sum}e_{\rm{IPS}}-{\textstyle\sum}e\big|=\mytextbf{0.8}$};
\node at (0*\toyLColumnW,\toyEIBTextY) {Error imputation $\hat{e}$.};
\node at (0*\toyLColumnW,\toyIPSTextY) {Propensity estimation $\hat{p}$.};
\node at (1.07*\toyLColumnW,-\toySTextY) {$\big|{\textstyle\sum}e_{\rm{DR}}-{\textstyle\sum}e\big|=\mytextbf{0.1}$};
\node at (0*\toyLColumnW,\toyEIBMissTY) {Missing data models.};

% \draw [->,solid,thick] (-\toyArrowLeftBX*\toyLColumnW,\toyLMatrixY)--(-\toyArrowLeftEX*\toyLColumnW,\toyLMatrixY);
% \draw [->,solid,thick] (-\toyArrowLeftBX*\toyLColumnW,-\toyLMatrixY)--(-\toyArrowLeftEX*\toyLColumnW,-\toyLMatrixY);

\node [rectangle] at (-\toyLSquareLTX*\toyLColumnW,\toyLSquareEIBY*\toyLMatrixY) {\normalsize EIB.};
\node [rectangle] at (-\toyLSquareLTX*\toyLColumnW,-\toyLSquareIPSY*\toyLMatrixY) {\normalsize IPS.};
\node [rectangle] at (\toyLSquareRTX*\toyLColumnW,\toyLSquareEIBY*\toyLMatrixY) {\normalsize DR (Ours).};
\node [rectangle] at (1.06*\toyLColumnW,\toyIPSTextY) {\emph{Note}: \mytextbf{0.1} is a bias.};



Most methods for reducing such bias involve an unbiased error estimator whose unbiasedness largely relies on a single missing data model.
One major issue with these methods is the lack of robustness to the missing data model's inaccuracy, and thus they can severely biased when such inaccuracy occurs.
Moreover, exiting methods usually ignore the variance of the estimator at the training stage, which can make the true error arbitrarily larger than the training error.
To address these issues, we propose double robust collaborative filtering (DRCF), a general framework to jointly minimize a double robust (DR) estimator and a variance regularizer.
The DR estimator obtains double robustness by combining two missing data models to ensure its unbiasedness so long as one of them is accurate.
The variance regularizer controls the variance of the DR estimator by favoring the predictions with the tightest upper bound on the true error.
We instantiate DRCF with matrix factorization, for which we propose an efficient variance-regularized training algorithm.
Extensive experiments show that DRCF achieves a significant decrease of prediction error on real-world datasets and the DR estimator effectively alleviates the bias on a semi-synthetic dataset.

We often observe discrepancies between a new recommender system's offline performance improvements on historical data and its online business gains in a real production environment. There are mainly two causes for such discrepancies. The first cause is the bias of performance estimators in offline learning, e.g., the expected estimation of rating prediction error differs from the true error. Existing estimators largely rely on a single missing data model to guarantee its unbiasedness and thus can be severely biased when the missing data model is inaccurate. To be less biased in such cases, we propose a double robust (DR) estimator that fuses two missing data models to guarantee its unbiasedness when one of them is accurate. The second cause is the variance of these estimators, e.g., the estimated errors vary across different samples of a rating dataset, which is usually ignored in existing methods. To address this problem, we further propose a general framework double robust collaborative filtering (DRCF) to jointly minimize the DR estimator and its empirical variance. Under this framework, we propose an efficient variance-regularized training algorithm based on matrix factorization. Extensive experiments show that DRCF achieves a significant decrease of prediction error on real-world datasets and the DR estimator effectively alleviates the bias on a semi-synthetic dataset.

Missing data in rating-based recommender systems is usually missing not at random.
Ignoring missing data can result in a large error of rating prediction by inducing a bias into learning (minimizing an incorrect error function) and evaluation (over- or under-estimating prediction error).
Most existing methods for reducing such bias use a single missing data model, i.e., an error imputation model or a propensity estimation model.
However, these methods can also be severely biased in case where the missing data model used is inaccurate.
To be less biased in such cases.

\newcommand{\toyColumnW}{0.33\linewidth}
\newcommand{\toySingleH}{0.20cm}
\newcommand{\toyDoubleH}{0.60cm}
\newcommand{\toyFMatrixY}{-0.00cm}
\newcommand{\toyFTextY}{-0.60cm}
\newcommand{\toySMatrixY}{-1.35cm} % 0.60 + 0.20/2 + 0.65
\newcommand{\toySTextY}{-2.10cm} % 1.35 + 0.75
\newcommand{\toyTMatrixY}{-3.05cm} % 2.10 + 0.60/2 + 0.65
\newcommand{\toyTTextY}{-3.80cm} % 3.05 + 0.75
\newcommand{\toyFLineY}{0.50cm}
\newcommand{\toySLineY}{-2.55cm} % 2.10 + 0.60/2 + 0.15
\newcommand{\toyTLineY}{-2.60cm} % 2.55 + 0.05
\newcommand{\toyBLineY}{-4.25cm} % 3.80 + 0.60/2 + 0.15
\tikzstyle{toyExampleStyle} = [
  every left delimiter/.style={xshift=0.1cm},
  every right delimiter/.style={xshift=-0.1cm},
]
\tikzstyle{toyMatrixStyle} = [
  column sep=-0.2ex, inner sep=0.0pt, matrix of math nodes, 
  nodes={ % draw, very thin,
    minimum height=1.2em, minimum width=1.8em,
    inner sep=0.0pt, outer sep=0.0pt,},
  left delimiter={[}, right delimiter={]},
]
\begin{figure}[t]
\small
% \scriptsize
\centering
\thinmuskip=0mu \medmuskip=0mu \thickmuskip=1mu
\begin{subfigure}[b]{1.0\linewidth}
\begin{tikzpicture}[toyExampleStyle]
% \draw[help lines] (0.0,0.0) grid (1.0,-1.0);

\node at (\toyColumnW, 0.70) {
  $^{*}$Row and column denote user and item (matrix indices omitted).
};
\matrix (R) [toyMatrixStyle] at (0*\toyColumnW,\toyFMatrixY) {
  1 & 1 & 1 & 5 \\
  1 & 1 & 1 & 5 \\
};
\node at (0*\toyColumnW,\toyFTextY) {
  \begin{minipage}[c][\toySingleH][c]{\toyColumnW}
    \begin{center}$r$: The true rating.\end{center}
  \end{minipage}
};
\matrix (R_hat) [toyMatrixStyle] at (1*\toyColumnW,\toyFMatrixY) {
  3 & 3 & 3 & 4 \\
  3 & 3 & 3 & 4 \\
};
\node at (1*\toyColumnW,\toyFTextY) {
  \begin{minipage}[c][\toySingleH][c]{\toyColumnW}
    \begin{center}$\hat{r}$: Predicted rating.\end{center}
  \end{minipage}
};
\matrix (P_hat) [toyMatrixStyle] at (2*\toyColumnW,\toyFMatrixY) {
  0.2 & 0.2 & 0.2 & 0.3 \\
  0.2 & 0.2 & 0.2 & 0.3 \\
};
\node at (2*\toyColumnW,\toyFTextY) {
  \begin{minipage}[c][\toySingleH][c]{\toyColumnW}
    \begin{center}$\hat{p}$: Propensity.\end{center}
  \end{minipage}
};

\matrix (O) [toyMatrixStyle] at (0*\toyColumnW,\toySMatrixY) {
  1 & 0 & 0 & 0 \\
  0 & 0 & 0 & 1 \\
};
\node at (0*\toyColumnW,\toySTextY) {
  \begin{minipage}[c][\toyDoubleH][c]{\toyColumnW}
    \begin{center}
      $o=0$: $r$ missing.\\
      $o=1$: $r$ observed.
    \end{center}
  \end{minipage}
};
\matrix (E) [toyMatrixStyle] at (1*\toyColumnW,\toySMatrixY) {
  2 & 2 & 2 & 1 \\
  2 & 2 & 2 & 1 \\
};
\node at (1*\toyColumnW, \toySTextY) {
  \thickmuskip=5mu
  \begin{minipage}[c][\toyDoubleH][c]{\toyColumnW}
    \begin{center}
      $e=|\hat{r}-r|$ \\
      $e$: The true error.
    \end{center}
  \end{minipage}
};
\matrix (E_hat) [toyMatrixStyle] at (2*\toyColumnW,\toySMatrixY) {
  1.5 & 1.5 & 1.5 & 0.5 \\
  1.5 & 1.5 & 1.5 & 0.5 \\
};
\node at (2*\toyColumnW,\toySTextY) {
  \thickmuskip=5mu
  \begin{minipage}[c][\toyDoubleH][c]{\toyColumnW}
    \begin{center}
      $\hat{e}=|\hat{r}-4.5|$ \\
      $\hat{e}$: Imputed error.
    \end{center}
  \end{minipage}
};

\draw [dashed,semithick] (-0.47*\toyColumnW,\toyFLineY)--(2.47*\toyColumnW,\toyFLineY);

\draw [dashed,semithick] (-0.47*\toyColumnW,\toySLineY)--(2.47*\toyColumnW,\toySLineY);

\draw [dotted,red,thick] (1.5*\toyColumnW,\toyTLineY)--(2.47*\toyColumnW,\toyTLineY)--(2.47*\toyColumnW,\toyBLineY)--(1.5*\toyColumnW,\toyBLineY)--cycle;

\matrix (EIB) [toyMatrixStyle] at (0*\toyColumnW,\toyTMatrixY) {
  2 & 1.5 & 1.5 & 0.5 \\
  1.5 & 1.5 & 1.5 & 1 \\
};
\node at (0*\toyColumnW,\toyTTextY) {
  \begin{minipage}[c][\toyDoubleH][c]{\toyColumnW}
    \begin{center}
      $e_{\rm{EIB}}=\hat{e}+oe-o\hat{e}$ \\
      $\big|{\textstyle\sum}e_{\rm{EIB}}-{\textstyle\sum}e\big|=3$
    \end{center}
  \end{minipage}
};
\matrix (IPS) [toyMatrixStyle] at (1*\toyColumnW,\toyTMatrixY) {
  10 & 0 & 0 & 0 \\
  0 & 0 & 0 & 3.3 \\
};
\node at (1*\toyColumnW,\toyTTextY) {
  \begin{minipage}[c][\toyDoubleH][c]{\toyColumnW}
    \begin{center}
      $e_{\rm{IPS}}=oe/\hat{p}$ \\
      $\big|{\textstyle\sum}e_{\rm{IPS}}-{\textstyle\sum}e\big|=0.7$
    \end{center}
  \end{minipage}
};
\matrix (DR) [toyMatrixStyle] at (2*\toyColumnW,\toyTMatrixY) {
  4 & 1.5 & 1.5 & 0.5 \\
  1.5 & 1.5 & 1.5 & 2.2 \\
};
\node at (2*\toyColumnW,\toyTTextY) {
  \begin{minipage}[c][\toyDoubleH][c]{\toyColumnW}
    \begin{center}
      $e_{\rm{DR}}=\hat{e}+o(e-\hat{e})/\hat{p}$ \\
      $\big|{\textstyle\sum}e_{\rm{DR}}-{\textstyle\sum}e\big|=\mytextbf{0.2}$
    \end{center}
  \end{minipage}
};
\end{tikzpicture}
\end{subfigure}
\caption{
  Given the partially observed true ratings (indicated by $o$), our DR method ($e_{\rm{DR}}$) for estimating the true error ($e$) reaches a smaller bias (\mytextbf{0.2}) than the EIB ($e_{\rm{EIB}}$) and IPS ($e_{\rm{IPS}}$) methods.
}
\label{fig:toy example}
\end{figure}  



The DR estimator is unbiased so long as either propensity estimation or error imputation is accurate, a property often referred to as double robustness.
The double robustness is achieved by cancelling the bias induced by inaccurate propensity estimation with accurate error imputation and vice versa.
To see this, we first assume that the propensity estimation is accurate ($\anEstPropensity=\aTruePropensity$).
Under the conditional independence assumption, we can write the expectation of the DR estimator defined in Eq.~\ref{equ:independence propensity dr estimator} as

\begin{equation*}
% \hspace*{-0.04cm}
\begin{aligned}
\expection_{\observations}[\drEstimator]
=\frac{1}{\numUsersItems}\bAbbrSumUsersItems
\expection_{\observations}
\Bigg[
  \frac{\anObservation\aTrueError}{\anEstPropensity}+
  \frac{(\anEstPropensity-\anObservation)\anEstError}{\anEstPropensity}
\Bigg]
&\\
\quad=\frac{1}{\numUsersItems}\bAbbrSumUsersItems
\frac{\aTruePropensity\aTrueError}{\anEstPropensity}+
\frac{1}{\numUsersItems}\bAbbrSumUsersItems
\frac{(\anEstPropensity-\aTruePropensity)\anEstError}{\anEstPropensity}
\text{,}
&
\end{aligned}
\end{equation*}%

which equals the risk $\trueRisk$ as the second term vanishes when $\anEstPropensity=\aTruePropensity$.
Then, we assume that the error imputation is accurate ($\anEstError=\aTrueError$).
Under the conditional independence assumption, we can write the expectation of the DR estimator defined in Eq.~\ref{equ:independence imputation dr estimator} as
which equals the risk $\trueRisk$ as the second term vanishes when $\anEstError=\aTrueError$.
When both propensity estimation and error imputation are inaccurate, we derive the bias of the DR estimator as follows.

\begin{equation*}
\begin{aligned}
\expection_{\observations}[\drEstimator]
=\frac{1}{\numUsersItems}\bAbbrSumUsersItems
\expection_{\observations}
\Bigg[
  \anEstError+
  \frac{\anObservation(\aTrueError-\anEstError)}{\anEstPropensity}
\Bigg]
&\\
\quad=\frac{1}{\numUsersItems}\bAbbrSumUsersItems\anEstError+
\frac{1}{\numUsersItems}\bAbbrSumUsersItems
\frac{\aTruePropensity(\aTrueError-\anEstError)}{\anEstPropensity}
\text{,}
&
\end{aligned}
\end{equation*}%


Most existing work on rating-based recommender systems does not explicitly considers the MNAR nature of rating data~\cite{adomavicius2005toward,salakhutdinov2007restricted}.
For example, some of the most successful methods are based on matrix factorization, which predicts ratings by factorizing observed ratings into latent factors for users and items~\cite{bell2007chasing,mnih2008probabilistic}.
More recently, autoencoders have been adapted for rating prediction by reconstructing a user's ratings given the user's historical ratings as input~\cite{sedhain2015autorec,strub2015collaborative}.
By comparing against these methods, we show that it is beneficial to model the MNAR nature of rating data but inaccurately modeling MNAR data can lead to an even worse accuracy.

Existing work dealing with MNAR data models missing data with a propensity model that estimates the probability of a rating to be missing~\cite{hernandez2014probabilistic,schnabel2016recommendations}.
For example, Marlin and Zemel combines a propensity model with a probabilistic model for complete data~\cite{marlin2007collaborative,marlin2009collaborative}
An alternative method is to model missing data with an imputation model that imputes some rating values for missing data~\cite{lim2015top}.
For example, Steck considers performance measures that can be estimated without bias from MNAR data based on an imputation model~\cite{steck2010training,steck2011item}.
Both the propensity and imputation-based methods are vulnerable to inaccurate models of missing data, which is what we aim to deal with in this paper.

In addition to rating prediction, another popular recommendation problem is item ranking~\cite{hu2008collaborative,he2016fast}.
The problem of item ranking is to provide a ranking list of items to users~\cite{rendle2009bpr,he2017neural}.
The accuracy for item ranking may suffer with the presence of biased data~\cite{ai2018unbiased,joachims2017unbiased}.
We leave the problem item ranking with double robustness for future work.


We use the following two methods for propensity estimation~\cite{schnabel2016recommendations}.
\begin{enumerate}[leftmargin=*,noitemsep,topsep=0pt]
\item \mytextbf{Naive Bayes}.
Suppose propensities are conditioned on the true ratings only, based on Bayes theorem, we have
\begin{equation*}
\anEstPropensity
=P(\anObservation=1|\aTrueRating)
=\frac{P(\aTrueRating|\anObservation=1)P(\anObservation=1)}{P(\aTrueRating)}
\text{.}
\end{equation*}%
We estimate $P(\aTrueRating|\anObservation=1)$ and $P(\anObservation=1)$ by maximum likelihood on MNAR data.
To estimate $P(\aTrueRating)$, we need to use a small sample of MAR data.
\item \mytextbf{Logistic Regression}.
Given a vector $\observedFeature$ that encodes all observable features about a user-item pair, we estimate propensities based on logistic regression as follows,
\begin{equation*}
\anEstPropensity=\sigma(\logRegrFeatWeight^\transpose\observedFeature+\logRegrUserBias+\logRegrItemBias)
\text{.}
\end{equation*}%
Here, $\sigma(\cdot)$ is the sigmoid function. $\logRegrFeatWeight$, $\logRegrUserBias$, and $\logRegrItemBias$ are trainable parameters.
\end{enumerate}

the SNIPS estimator~\cite{swaminathan2015self} defined as.
\begin{equation*}
\snipsEstimator=
\frac{1}{\verbSumUsersItems\frac{\anObservation}{\anEstPropensity}}
\verbSumUsersItems\frac{\anObservation\aTrueError}{\anEstPropensity}
\text{.}
\end{equation*}%
